Independent scalability is one of the main advantages of microservices, but it’s nonetheless challenging. In monolithic architecture, straightforward scaling approaches such as load balancing are relatively easy to implement. After all, the app is a single unit and one only needs to add more resources to fit the volume. There’s no independent scaling of each component, separately. That’s not the way it works in microservices.  

For an effective scaling of microservices-based apps, engineers must track performance and efficiency goals. While microservices design includes known best practices such as loose (but not too loose) coupling, API-first design, continuous integration and deployment, fault tolerance, EDA (event-driven architecture), security, specific monitoring capabilities and more, some best practices are especially important for microservices scalability: 

- **Use a container orchestration platform**. Container orchestration platforms such as [Kubernetes](https://gethelios.dev/blog/kubernetes-monitoring-opentelemetry/) can help to automate the scaling of microservices by ensuring that microservices are scaled up or down as needed. 
- **Use a service mesh**. A service mesh helps engineering teams run microservices at scale by offering a more flexible release process (for example, support for canary deployments, A/B testing, and blue/green deployments) availability, and resilience (for example, set up retries, failovers, circuit breakers, and fault injection).
- **Use load balancers**. This will help you distribute traffic across multiple microservices and prevent any single microservice from becoming overloaded. Popular load balancers include HAProxy, Nginx, Amazon Elastic Load Balancing (ELB), Azure Load Balancer, and Google Cloud Load Balancing. 
- **Use distributed tracing**. A dedicated monitoring and observability tool that enables [distributed tracing](https://gethelios.dev/distributed-tracing/) and is based on code instrumentation will track the flows between microservices, quickly identify issues and direct you to the root cause fast. Tools include Jaeger, Zipkin, New Relic, and [Helios](https://gethelios.dev/) (that’s us, more info is shared below). 
- **Use decoupled architecture**. Decoupled microservices can be scaled independently of each other.
- **Start small and scale up as needed**. It is not always necessary to scale microservices to their maximum capacity; it is often better to start small and scale up as needed, to avoid over-provisioning resources and to save costs.
- **Use autoscalers**. Autoscalers can help to automatically scale microservices up or down as needed. This ensures that microservices are scaled efficiently and that costs are kept under control. For example, the Kubernetes Horizontal Pod Autoscaler (HPA) can be used to automatically scale pods up or down based on the CPU usage of the pods. 
- **Have a contingency plan**. Know ahead what steps to take in case a microservice fails. Use tooling that will minimize MTTR – Read more on: [How we use trace-based alerts to reduce MTTR](https://gethelios.dev/blog/how-we-use-trace-based-alerts-to-speed-up-mttr-and-improve-developer-productivity/)